tunnel:
  vps-host: appf4s.io.vn
  vps-user: root
  vps-password: ledinhde788De
  app-f4-pass: f4security
  sql-host: sql.microservices.appf4s.io.vn
  # sql-host: localhost

  sql-port: 3307

logging:
  level:
    ROOT: DEBUG
    tech.jhipster: DEBUG
    org.hibernate.SQL: DEBUG
    com.ridehub.route: DEBUG

management:
  health:
    elasticsearch:
      enabled: false
  zipkin:
    tracing:
      endpoint: http://${tunnel.vps-host}:9411/api/v2/spans
  tracing:
    sampling:
      probability: 1.0

# âœ… springdoc must be top-level (NOT under spring)
springdoc:
  api-docs:
    enabled: true

spring:
  application:
    name: ${server.name}

  devtools:
    restart:
      enabled: true
      additional-exclude: static/**
    livereload:
      enabled: false

  jackson:
    serialization:
      indent-output: true

  cloud:
    stream:
      poller:
        fixed-delay: 100
        max-messages-per-poll: 1
      # ---- Kafka binder (shared client config) ----
      kafka:
        binder:
          brokers: ${tunnel.vps-host}:9092
          auto-create-topics: true
          auto-add-partitions: true
          min-partition-count: 3
          replication-factor: 1

          # All raw Kafka client props belong under `configuration`
          configuration:
            security.protocol: SSL
            ssl.endpoint.identification.algorithm: ""
            # Vault-based JKS configuration for remote access
            ssl.truststore.location: ${VAULT_KAFKA_TRUSTSTORE_LOCATION:file:${server.dev-config-folder}/tls/kafka.client.truststore.jks}
            ssl.truststore.password: ${VAULT_KAFKA_TRUSTSTORE_PASSWORD:${tunnel.app-f4-pass}}
            ssl.keystore.location: ${VAULT_KAFKA_KEYSTORE_LOCATION:file:${server.dev-config-folder}/tls/kafka.broker.keystore.jks}
            ssl.keystore.password: ${VAULT_KAFKA_KEYSTORE_PASSWORD:${tunnel.app-f4-pass}}
            ssl.key.password: ${VAULT_KAFKA_KEY_PASSWORD:${tunnel.app-f4-pass}}
            connections.max.idle.ms: 540000
            metadata.max.age.ms: 300000
            reconnect.backoff.ms: 1000
            reconnect.backoff.max.ms: 32000
            request.timeout.ms: 40000
            # Default consumer tuning
            group.id: ${kafka.utility.service-name:${server.name}}-group
            enable.auto.commit: false
            auto.offset.reset: earliest
            fetch.min.bytes: 1024
            fetch.max.bytes: 52428800
            fetch.max.wait.ms: 100
            max.poll.records: 200
            max.poll.interval.ms: 300000
            session.timeout.ms: 45000
            heartbeat.interval.ms: 15000
            partition.assignment.strategy: org.apache.kafka.clients.consumer.CooperativeStickyAssignor
            receive.buffer.bytes: 65536
            send.buffer.bytes: 131072
            retry.backoff.ms: 1000

            # Default producer tuning
            acks: 1
            retries: 3
            enable.idempotence: false
            batch.size: 32768
            linger.ms: 10
            buffer.memory: 67108864
            compression.type: snappy
            max.in.flight.requests.per.connection: 3
            delivery.timeout.ms: 120000
          producer-properties:
            key.serializer: org.apache.kafka.common.serialization.StringSerializer
            value.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
            schema.registry.url: http://appf4s.io.vn:8081
            latest.compatibility.strict: false
          consumer-properties:
            key.deserializer: org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
            value.deserializer: org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
            spring.deserializer.key.delegate.class: org.apache.kafka.common.serialization.StringDeserializer
            spring.deserializer.value.delegate.class: io.confluent.kafka.serializers.KafkaAvroDeserializer
            schema.registry.url: http://appf4s.io.vn:8081
            specific.avro.reader: true
  data:
    redis:
      host: ${REDIS_HOST:${tunnel.vps-host}}       # appf4s.io.vn
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD:${tunnel.app-f4-pass}}  # f4security
      timeout: 3000
  datasource:
    type: com.zaxxer.hikari.HikariDataSource
    # Use envs and fallback defaults; DB name defaults to app name
    url: "jdbc:mysql://${tunnel.sql-host}:${server.sql-port}/${server.sql-name}?useUnicode=true&characterEncoding=utf8&useSSL=false&useLegacyDatetimeCode=false&createDatabaseIfNotExist=true&allowPublicKeyRetrieval=true&allowLoadLocalInfile=true&rewriteBatchedStatements=true&useServerPrepStmts=true&cachePrepStmts=true&prepStmtCacheSize=250&prepStmtCacheSqlLimit=2048&connectTimeout=20000&socketTimeout=600000"
    username: root
    password:
    hikari:
      poolName: Hikari
      auto-commit: false
      data-source-properties:
        cachePrepStmts: true
        prepStmtCacheSize: 250
        prepStmtCacheSqlLimit: 2048
        useServerPrepStmts: true

  elasticsearch:
    uris: http://${tunnel.vps-host}:9200

  liquibase:
    contexts: dev, faker
    parameters:
      csv_path: ${server.dev-config-folder}/data

  messages:
    cache-duration: PT1S

  thymeleaf:
    cache: false

  security:
    oauth2:
      client:
        provider:
          oidc:
            issuer-uri: https://keycloak.${tunnel.vps-host}/realms/jhipster
        registration:
          oidc:
            client-id: web_app
            client-secret: 0TnpRknqjQYngbnbRW7hKECA8TbR4D7V
            scope: openid, profile, email, offline_access # last one for refresh tokens
kafka:
  utility:
    enabled: true
    service-name: ${server.name}
    environment: ${spring.profiles.active:dev}

    thread-pool:
      core-size: 4
      max-size: 12
      queue-capacity: 50
      keep-alive-seconds: 60
      thread-name-prefix: kafka-util-
      rejection-policy: CALLER_RUNS

    retry:
      enabled: true
      max-attempts: 2
      backoff-period: 1000
      backoff-multiplier: 2.0
      max-backoff-period: 10000
      retry-exceptions:
        - org.apache.kafka.common.errors.RetriableException
        - org.springframework.kafka.support.KafkaException
        - java.net.SocketTimeoutException
        - javax.net.ssl.SSLException

    dlq:
      enabled: true
      topic-suffix: .dlq
      max-retries-before-dlq: 2
      include-headers: true
      include-stack-trace: false

    topics:
      auto-create: true
      default-partitions: 3
      default-replication-factor: 1
      configurations:
        route-events:
          partitions: 6
          replication-factor: 1
          retention-ms: 259200000
          cleanup-policy: delete
          segment-ms: 86400000

jhipster:
  cache:
    redis:
      expiration: 3600
      server: redis://:${tunnel.app-f4-pass}@${tunnel.vps-host}:6379
      cluster: false
    hazelcast: # Hazelcast distributed cache
      time-to-live-seconds: 3600
      backup-count: 1
  logging:
    use-json-format: false
    logstash:
      enabled: false
      host: ${tunnel.vps-host}
      port: 5000
      ring-buffer-size: 512

ridehub:
  services:
    booking: msbooking
    promotion: mspromotion
    user: msuser
    route: msroute
    ticket: msticket
  feign:
    scans:
      - basePackage: com.ridehub.msbooking.client.api
        serviceId: ${ridehub.services.booking}
      - basePackage: com.ridehub.mspromotion.client.api
        serviceId: ${ridehub.services.promotion}
      - basePackage: com.ridehub.msuser.client.api
        serviceId: ${ridehub.services.user}
      - basePackage: com.ridehub.msroute.client.api
        serviceId: ${ridehub.services.route}
  s2s:
    token-url: https://keycloak.${tunnel.vps-host}/realms/jhipster/protocol/openid-connect/token
    client-id: ms-booking
    client-secret: 0TnpRknqjQYngbnbRW7hKECA8TbR4D7V
    scope:
